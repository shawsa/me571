{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "# Prob2 : Performance results\n",
    "<hr/>\n",
    "\n",
    "This note book assumes that you have run your code for processor counts $[1,2,4,8]$ and have files `trap_1.out`, `trap_2.out` and so on. \n",
    "\n",
    "First, we create a Panel of data collecting everything in the files you just created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy, pandas\n",
    "\n",
    "file_prefix = 'trap_'\n",
    "\n",
    "pdata = {}\n",
    "nprocs = [1,2,4,8, 16]\n",
    "for p in nprocs:\n",
    "    fname = file_prefix + '{:02d}'.format(p) + '.out'\n",
    "    try:\n",
    "        df = pandas.read_table(fname,names=['N','soln','err','t'],delim_whitespace=True)        \n",
    "    except:\n",
    "        print(\"File '{:s}' not found.\".format(fname))\n",
    "    else:\n",
    "        tname = 'p' + '{:02d}'.format(p)       \n",
    "        pdata[tname] = df\n",
    "        \n",
    "    \n",
    "panel = pandas.Panel(pdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can index panels as dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "panel['p02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at different slice of data.  For example, suppose we wanted to check our results across all processors for N=16384.  This corresponds to index value 4 (see above).  The N axis is the major axes, and so we can look across the \"cubed\" panel data using \n",
    "\n",
    "    panel.major_xs(4)    # Corresponds to N = 16384\n",
    "    \n",
    "Then, we look to see that we have virtually identical error results across all processors. Note that we transpose the data so that header labels are across the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "panel.major_xs(4).transpose()    # Choose layers of N values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also slice along the minor axis to see the timing results across all processors for our range of N values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "panel.minor_xs('t') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot timing results\n",
    "\n",
    "Using the Panel, we can easily plot all of the timing results in a single plot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_timing = panel.minor_xs('t') \n",
    "cols = ['N',*df_timing.columns]\n",
    "\n",
    "\n",
    "df_timing['N'] = panel['p01']['N'].astype('int')\n",
    "df_timing = df_timing[cols]\n",
    "df_timing.plot(x='N',logx=True,logy=True,style='.-',markersize=10)\n",
    "\n",
    "title(\"Timing results\",fontsize=18);\n",
    "xlabel(\"N\",fontsize=16)\n",
    "ylabel(\"Time (s)\",fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "## Strong scaling\n",
    "\n",
    "If an algorithm scales well, we expect that adding more processors to a problem of fixed size should speed up the calculation.  If a code were \"embarrassingly parallel\", we expect two processors to take half as much time as one processor, 4 processors to take a quarter of the time, and so on.  We call this type of scaling \"strong\" scaling.  \n",
    "\n",
    "For strong scaling, we compare timings for a fixed value of $N$.   We will choose one of the larger values to see better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 18    # Choose N corresponding to index=18\n",
    "N = int(panel['p01']['N'][idx])\n",
    "\n",
    "procs = array([1,2,4,8])\n",
    "\n",
    "df_strong = panel.major_xs(idx).transpose()    \n",
    "df_strong['p'] = procs\n",
    "df_strong[['p','soln','err','t']].style.set_caption(\"N = {:d}\".format(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the strong scaling results and show the best-fit line to get an estimate of the speed-up.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_strong.plot(x='p',y='t',logx=True,logy=True,style='.-',markersize=15)\n",
    "\n",
    "# Plot best-fit speed-up line\n",
    "t_strong = array(df_strong['t'])\n",
    "c = polyfit(log(procs[:-1]),log(t_strong[:-1]),1)\n",
    "loglog(procs,exp(polyval(c,log(procs))),'r--')\n",
    "\n",
    "legend(['Time (slope={:6.2f})'.format(c[0]),'Speed-up'])\n",
    "title('Speed-up',fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weak scaling\n",
    "\n",
    "If an algorithm scales well, we expect to be able to solve bigger problems by adding more processors.  For example, if we double the size of the problem, and double the number of processors, we expect the code to take the same time as the original problem.  This sort of scaling is called \"weak scaling\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure()\n",
    "clf()\n",
    "df_weak = panel.minor_xs('t')\n",
    "idx = 14     # Start with 'N' index;  shift by one as we increase the processor count\n",
    "\n",
    "t_weak = array([df_weak[c][14+i] for i,c in enumerate(df_weak.columns)])\n",
    "\n",
    "semilogx(procs,t_weak,'.-',markersize=15)\n",
    "semilogx(procs,[t_weak[0]]*4,'k--')\n",
    "title('Weak scaling', fontsize=18)\n",
    "xlabel('Cores')\n",
    "ylabel(\"Time (s)\")\n",
    "legend(['Time (s)','Perfect scaling'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency\n",
    "\n",
    "When we add more processors, we expect some overhead associated with more communication.  This is captured somewhat in the weak scaling results, but what is not shown is how quickly the efficiency drops off.  \n",
    "\n",
    "Efficiency plots can often highlight poor scaling reslts that are not obvious from strong scaling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure()\n",
    "clf()\n",
    "\n",
    "# Efficiency\n",
    "E = t_strong[0]/(procs*t_strong)*100\n",
    "\n",
    "semilogx(procs,E,'.-',markersize=15)\n",
    "semilogx(procs,[100]*4,'k--',linewidth=2)\n",
    "\n",
    "xlabel('Cores',fontsize=16)\n",
    "ylabel('Efficiency (%)',fontsize=16)\n",
    "title(\"Efficiency (%)\");\n",
    "legend(['Time (s)', 'Perfect efficiency'])\n",
    "xlim([1/sqrt(2), 2**4.5])\n",
    "ylim([10,110])\n",
    "grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
